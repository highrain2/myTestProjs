{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bOChJSNXtC9g"
   },
   "source": [
    "# Data and Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OLIxEDq6VhvZ"
   },
   "source": [
    "So far we've seen a variety of different models on different datasets for different tasks (regression/classification) and we're going to learn about more algorithms in subsequent lessons. \n",
    "But we've ignored a fundamental concept about data and modeling: quality and quantity. \n",
    "In a nutshell, a machine learning model consumes input data and produces predictions. \n",
    "The quality of the predictions directly corresponds to the quality and quantity of data you train the model with; garbage in, garbage out.\n",
    "\n",
    "<img src=\"figures/nutshell.png\" width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FLH7kzZl8wnf"
   },
   "source": [
    "# Set Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qAE9BjMH8x4q"
   },
   "source": [
    "We're going to go through all the concepts with concrete code examples. We'll first synthesize some data to train our models on. The task is to determine whether a tumor will be benign (harmless) or malignant (harmful) based on leukocyte (white blood cells) count and blood pressure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N9uu2nngKDrW",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now import the libraries\n",
    "from argparse import Namespace\n",
    "import collections\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gPHmsndLdUOH"
   },
   "outputs": [],
   "source": [
    "# Set Numpy and PyTorch seeds\n",
    "def set_seeds(seed, cuda):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if cuda:\n",
    "        torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "0-dXQiLlTIgz",
    "outputId": "d525f333-8024-48d3-ab6d-ea9507b9a94a"
   },
   "outputs": [],
   "source": [
    "# Arguments\n",
    "args = Namespace(\n",
    "    seed=1234,\n",
    "    cuda=False,\n",
    "    shuffle=True,\n",
    "    data_file=\"data/tumors.csv\",\n",
    "    reduced_data_file=\"data/tumors_reduced.csv\",\n",
    "    train_size=0.75,\n",
    "    test_size=0.25,\n",
    "    num_hidden_units=100,\n",
    "    learning_rate=1e-3,\n",
    "    num_epochs=100,\n",
    ")\n",
    "\n",
    "# Check CUDA\n",
    "if not torch.cuda.is_available():\n",
    "    args.cuda = False\n",
    "args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "print(\"Using CUDA: {}\".format(args.cuda))\n",
    "\n",
    "# Set seeds\n",
    "set_seeds(seed=args.seed, cuda=args.cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RV2IddoZde-r"
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5wDazzQdaoy2"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "y6LNWmoidh8q",
    "outputId": "a2ee99a4-8c89-41d4-d482-7e098b097d14"
   },
   "outputs": [],
   "source": [
    "# Raw data\n",
    "df = pd.read_csv(args.data_file, header=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YVo6CuZLC3h2"
   },
   "outputs": [],
   "source": [
    "def plot_tumors(df):\n",
    "    i = 0; colors=['r', 'b']\n",
    "    for name, group in df.groupby(\"tumor\"):\n",
    "        plt.scatter(group.leukocyte_count, group.blood_pressure, edgecolors='k',\n",
    "                   color=colors[i]); i += 1\n",
    "    plt.xlabel('leukocyte count')\n",
    "    plt.ylabel('blood pressure')\n",
    "    plt.legend(['0 - benign', '1 - malignant'], loc=\"upper right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 361
    },
    "colab_type": "code",
    "id": "nXFUmnfte6z6",
    "outputId": "2b797875-3e15-4e67-ed8c-1585e9e54ba9"
   },
   "outputs": [],
   "source": [
    "# Plot data\n",
    "plot_tumors(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "237OzHqlNQ-D"
   },
   "outputs": [],
   "source": [
    "# Convert to PyTorch tensors\n",
    "X = df.as_matrix(columns=['leukocyte_count', 'blood_pressure'])\n",
    "y = df.as_matrix(columns=['tumor'])\n",
    "X = torch.from_numpy(X).float()\n",
    "y = torch.from_numpy(y.ravel()).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "0pahDv9WLD2S",
    "outputId": "e3e7a63a-e027-4d04-8c54-8d658419750d"
   },
   "outputs": [],
   "source": [
    "# Shuffle data\n",
    "shuffle_indices = torch.LongTensor(random.sample(range(0, len(X)), len(X)))\n",
    "X = X[shuffle_indices]\n",
    "y = y[shuffle_indices]\n",
    "\n",
    "# Split datasets\n",
    "test_start_idx = int(len(X) * args.train_size)\n",
    "X_train = X[:test_start_idx] \n",
    "y_train = y[:test_start_idx] \n",
    "X_test = X[test_start_idx:] \n",
    "y_test = y[test_start_idx:]\n",
    "print(\"We have %i train samples and %i test samples.\" % (len(X_train), len(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "owLnzReJJdpj"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zlPe1lXEJfcA"
   },
   "source": [
    "Let's fit a model on this synthetic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0WhYfDOjJdIV"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nTtsFHZY_G45"
   },
   "outputs": [],
   "source": [
    "# Multilayer Perceptron \n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x_in, apply_softmax=False):\n",
    "        a_1 = F.relu(self.fc1(x_in)) # activaton function added!\n",
    "        y_pred = self.fc2(a_1)\n",
    "\n",
    "        if apply_softmax:\n",
    "            y_pred = F.softmax(y_pred, dim=1)\n",
    "\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1kXlfHpPJ5Vq"
   },
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = MLP(input_dim=len(df.columns)-1, \n",
    "            hidden_dim=args.num_hidden_units, \n",
    "            output_dim=len(set(df.tumor)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ncxbef0yJ6pD"
   },
   "outputs": [],
   "source": [
    "# Optimization\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=args.learning_rate) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "srlaBr8oiftE"
   },
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "def get_accuracy(y_pred, y_target):\n",
    "    n_correct = torch.eq(y_pred, y_target).sum().item()\n",
    "    accuracy = n_correct / len(y_pred) * 100\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "Mjg4u-zCK90q",
    "outputId": "cdcefbe6-fbdf-4cfb-de36-d365573d2ed5"
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "for t in range(args.num_epochs):\n",
    "    # Forward pass\n",
    "    y_pred = model(X_train)\n",
    "    \n",
    "    # Accuracy\n",
    "    _, predictions = y_pred.max(dim=1)\n",
    "    accuracy = get_accuracy(y_pred=predictions.long(), y_target=y_train)\n",
    "\n",
    "    # Loss\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "    \n",
    "    # Verbose\n",
    "    if t%20==0: \n",
    "        print (\"epoch: {0:02d} | loss: {1:.4f} | accuracy: {2:.1f}%\".format(\n",
    "            t, loss, accuracy))\n",
    "\n",
    "    # Zero all gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # Update weights\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wHCvuSEaK-2x"
   },
   "outputs": [],
   "source": [
    "# Predictions\n",
    "_, pred_train = model(X_train, apply_softmax=True).max(dim=1)\n",
    "_, pred_test = model(X_test, apply_softmax=True).max(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "5whE6K0rOmGN",
    "outputId": "0d895286-edda-4b8e-f520-ebb63d8fd070"
   },
   "outputs": [],
   "source": [
    "# Train and test accuracies\n",
    "train_acc = get_accuracy(y_pred=pred_train, y_target=y_train)\n",
    "test_acc = get_accuracy(y_pred=pred_test, y_target=y_test)\n",
    "print (\"train acc: {0:.1f}%, test acc: {1:.1f}%\".format(train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bzFb90SJOmI2"
   },
   "outputs": [],
   "source": [
    "# Visualization\n",
    "def plot_multiclass_decision_boundary(model, X, y):\n",
    "    x_min, x_max = X[:, 0].min() - 0.1, X[:, 0].max() + 0.1\n",
    "    y_min, y_max = X[:, 1].min() - 0.1, X[:, 1].max() + 0.1\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 101), np.linspace(y_min, y_max, 101))\n",
    "    cmap = plt.cm.Spectral\n",
    "    \n",
    "    X_test = torch.from_numpy(np.c_[xx.ravel(), yy.ravel()]).float()\n",
    "    y_pred = model(X_test, apply_softmax=True)\n",
    "    _, y_pred = y_pred.max(dim=1)\n",
    "    y_pred = y_pred.reshape(xx.shape)\n",
    "    plt.contourf(xx, yy, y_pred, cmap=plt.cm.Spectral, alpha=0.8)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, s=40, cmap=plt.cm.RdYlBu)\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ViwfNFOYRDkm"
   },
   "source": [
    "We're going to plot a white point, which we know belongs to the malignant tumor class. Our well trained model here would accurately predict that it is indeed a malignant tumor!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 335
    },
    "colab_type": "code",
    "id": "_oEf6XRmOsJE",
    "outputId": "34be9806-8b48-4c61-c5df-fe38a29ae6d5"
   },
   "outputs": [],
   "source": [
    "# Visualize the decision boundary\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Train\")\n",
    "plot_multiclass_decision_boundary(model=model, X=X_train, y=y_train)\n",
    "plt.scatter(np.mean(df.leukocyte_count), np.mean(df.blood_pressure), s=200, \n",
    "            c='b', edgecolor='w', linewidth=2)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Test\")\n",
    "plot_multiclass_decision_boundary(model=model, X=X_test, y=y_test)\n",
    "plt.scatter(np.mean(df.leukocyte_count), np.mean(df.blood_pressure), s=200, \n",
    "            c='b', edgecolor='w', linewidth=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o231eJaQPi5E"
   },
   "source": [
    "Great! We received great performances on both our train and test data splits. We're going to use this dataset to show the importance of data quality and quantity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pZ3rnGH8PtBu"
   },
   "source": [
    "# Data Quality and Quantity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ONRP3WQgR3zc"
   },
   "source": [
    "Let's remove some training data near the decision boundary and see how robust the model is now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "sU69PjH3Z4bm",
    "outputId": "a9d507a7-9f96-4bb2-81ac-35485f8ca5f5"
   },
   "outputs": [],
   "source": [
    "# Raw reduced data\n",
    "df_reduced = pd.read_csv(args.reduced_data_file, header=0)\n",
    "df_reduced.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 361
    },
    "colab_type": "code",
    "id": "1OwgEJSsZ4g5",
    "outputId": "5464cb82-b7a7-4cc2-e137-27379e6d5c27"
   },
   "outputs": [],
   "source": [
    "# Plot data\n",
    "plot_tumors(df_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r9xlQme0beTY"
   },
   "outputs": [],
   "source": [
    "# Convert to PyTorch tensors\n",
    "X = df_reduced.as_matrix(columns=['leukocyte_count', 'blood_pressure'])\n",
    "y = df_reduced.as_matrix(columns=['tumor'])\n",
    "X = torch.from_numpy(X).float()\n",
    "y = torch.from_numpy(y.ravel()).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "RerzDWJQbeVz",
    "outputId": "98b02a78-e164-4f79-9492-054feab9d55b"
   },
   "outputs": [],
   "source": [
    "# Shuffle data\n",
    "shuffle_indices = torch.LongTensor(random.sample(range(0, len(X)), len(X)))\n",
    "X = X[shuffle_indices]\n",
    "y = y[shuffle_indices]\n",
    "\n",
    "# Split datasets\n",
    "test_start_idx = int(len(X) * args.train_size)\n",
    "X_train = X[:test_start_idx] \n",
    "y_train = y[:test_start_idx] \n",
    "X_test = X[test_start_idx:] \n",
    "y_test = y[test_start_idx:]\n",
    "print(\"We have %i train samples and %i test samples.\" % (len(X_train), len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JCZ7yDl1OsdU"
   },
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = MLP(input_dim=len(df_reduced.columns)-1, \n",
    "            hidden_dim=args.num_hidden_units, \n",
    "            output_dim=len(set(df_reduced.tumor)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-IZ4YOKtSCRk"
   },
   "outputs": [],
   "source": [
    "# Optimization\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=args.learning_rate) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "7NBWLKDISDj8",
    "outputId": "83cff604-b034-4aea-e4b3-47a713209b07"
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "for t in range(args.num_epochs):\n",
    "    # Forward pass\n",
    "    y_pred = model(X_train)\n",
    "    \n",
    "    # Accuracy\n",
    "    _, predictions = y_pred.max(dim=1)\n",
    "    accuracy = get_accuracy(y_pred=predictions.long(), y_target=y_train)\n",
    "\n",
    "    # Loss\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "    \n",
    "    # Verbose\n",
    "    if t%20==0: \n",
    "        print (\"epoch: {0} | loss: {1:.4f} | accuracy: {2:.1f}%\".format(t, loss, accuracy))\n",
    "\n",
    "    # Zero all gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # Update weights\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uGWbZlhUSFOz"
   },
   "outputs": [],
   "source": [
    "# Predictions\n",
    "_, pred_train = model(X_train, apply_softmax=True).max(dim=1)\n",
    "_, pred_test = model(X_test, apply_softmax=True).max(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Gz2Sh4JpSFT9",
    "outputId": "8cb4c86b-0ff2-4548-a710-09883a8dc349"
   },
   "outputs": [],
   "source": [
    "# Train and test accuracies\n",
    "train_acc = get_accuracy(y_pred=pred_train, y_target=y_train)\n",
    "test_acc = get_accuracy(y_pred=pred_test, y_target=y_test)\n",
    "print (\"train acc: {0:.1f}%, test acc: {1:.1f}%\".format(train_acc, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 335
    },
    "colab_type": "code",
    "id": "DmTCz8OnSFRn",
    "outputId": "f3cf293c-b22b-49bf-d037-ca021376a5d7"
   },
   "outputs": [],
   "source": [
    "# Visualize the decision boundary\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Train\")\n",
    "plot_multiclass_decision_boundary(model=model, X=X_train, y=y_train)\n",
    "plt.scatter(np.mean(df.leukocyte_count), np.mean(df.blood_pressure), s=200, \n",
    "            c='b', edgecolor='w', linewidth=2)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Test\")\n",
    "plot_multiclass_decision_boundary(model=model, X=X_test, y=y_test)\n",
    "plt.scatter(np.mean(df.leukocyte_count), np.mean(df.blood_pressure), s=200, \n",
    "            c='b', edgecolor='w', linewidth=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kdP98xnlbvVn"
   },
   "source": [
    "This is a very scary but highly realistic scenario. Based on our reduced synthetic dataset, we have achieved a model that generalized really well on the test data. But when we ask for the prediction for the same white point earlier (which we known as a tumor), the prediction is now a benign tumor. We would have completely missed the tumor.\n",
    "\n",
    "**MODELS ARE NOT CRYSTAL BALLS** \n",
    "It's so important that before any machine learning, we really look at our data and ask ourselves if it is truly representative for the task we want to solve. The model itself may fit really well and generalize well on your data but if the data is of poor quality to begin with, the model cannot be trusted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yWzAC39adTwk"
   },
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cR45QpjQdY6N"
   },
   "source": [
    "Once you are confident that your data is of good quality and quantity, you can finally start thinking about modeling. The type of model you choose depends on many factors, including the task, type of data, complexity required, etc.\n",
    "\n",
    "<img src=\"figures/models1.png\" width=550>\n",
    "\n",
    "So once you figure out what type of model your task needs, start with simple models and then slowly add complexity. You don’t want to start with neural networks right away because that may not be right model for your data and task. Striking this balance in model complexity is one of the key tasks of your data scientists. **simple models → complex models**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "09_Data_and_Models",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
